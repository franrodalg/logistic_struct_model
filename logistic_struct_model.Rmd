---
title: "Analysing Measurements from Intervention-based Evaluation Studies"
output: html_notebook
---

## Setup

```{r}
if (!require(tidyverse)) {
  install.packages('tidyverse')
  library(tidyverse)
}
if (!require(lme4))
  install.packages('lme4')
if (!require(lmerTest))
  install.packages('lmerTest')
if (!require(emmeans))
  install.packages('emmeans')
if (!require(rbenchmark))
  install.packages('rbenchmark')
if(!require(patchwork)) {
  install.packages('patchwork')
  library(patchwork)
}
```

```{r}
set.seed(1986)
```

## Helper Functions

```{r}
get_ability <- function(x, l, z, w, x_num=2, l_num=2) {
  x <- x / (x_num - 1)
  l <- l / (l_num - 1)
  ability <- (0.1 + (x+1)*0.3 + ((l+1)*0.15) + (l*(1-x))*0.1 -
    (z)*0.1 - (z*l)*0.1 - (w*x)*0.3 - (z*w)*0.05)
  min(0.95, max(0.05, ability))
}
```

## Simulation parameters

```{r}
x_num <- 2
l_num <- 2
k_num <- 40
z_num <- 2
w_num <- 2
N <- 100
```

## Computation of Simulated Observations

```{r}
(abilities <- as_tibble(
    expand.grid(
      X=0:(x_num-1),
      L=0:(l_num-1),
      Z=0:(z_num-1),
      W=0:(w_num-1)
    )
  ) %>%
  rowwise() %>%
  mutate(
    feat_ext=paste0('e', X+1),
    learn_alg=paste0('l', L+1),
    conf_1=paste0('z', rep("'", Z)),
    conf_2=paste0('w', rep("'", W)),
    ability=get_ability(X, L, Z, W)) %>%
  ungroup() %>%
  select(-c(1:4)))


```

```{r}
(observations <- abilities %>% merge(
  tibble(samp=1:k_num) %>%
    mutate(difficulty = rnorm(k_num, 0, 0.1))) %>% 
  group_by(samp, feat_ext, learn_alg, conf_1, conf_2) %>%
  mutate(prob=max(0, min(1, ability*(1-difficulty)))) %>%
  merge(tibble(i=1:N))  %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(y=rbinom(1, 1, prob)) %>%
  ungroup() %>%
  select(samp, everything(), -i))
```

```{r}
(measurements <- observations %>%
  group_by(samp, feat_ext, learn_alg, conf_1, conf_2) %>%
  summarise(y=mean(y)))
```

```{r}
measurements %>%
    ggplot() +
    geom_boxplot(aes(x=feat_ext, y=y, color=learn_alg, fill=learn_alg),
               alpha=0.2, size=0.8) +
    facet_grid(rows=vars(conf_1), cols=vars(conf_2), labeller=label_both) +
    coord_cartesian(ylim=c(0,1)) +
    labs(x='Feature Extractor', y='Accuracy') +
    scale_color_discrete(name='Learning\nAlgorithm') +
    scale_fill_discrete(name='Learning\nAlgorithm') +
    theme_bw()
```

## Model Definition

```{r}
model <- y ~ learn_alg*feat_ext*conf_1 + learn_alg*feat_ext*conf_2 + 
  conf_1*conf_2 + (1 | samp)
```

## Linear Modelling

```{r}
linear_fit <- lmerTest::lmer(model, data=measurements)
```

```{r}
summary(linear_fit)
```

## Logistic Modelling

```{r}
logistic_fit <- lme4::glmer(
  model,
  family="binomial",
  data=observations,
  control=lme4::glmerControl(optimizer="bobyqa",
                            optCtrl=list(maxfun=1e6)))
```

```{r}
summary(logistic_fit)
```

## Interpretation

### Convert logistic estimates

```{r}
logit_inv <- function(x) { 1 / (1+exp(-x)) }
```

```{r}
data.frame(estimate=lme4::fixef(logistic_fit)) %>%
    rownames_to_column('parameter') %>%
    mutate(converted=logit_inv(estimate))
```

### Estimated Means

#### Linear

```{r}
(linear_means <- emmeans::emmeans(
  linear_fit, c('feat_ext', 'learn_alg', 'conf_1', 'conf_2')))
```

```{r}
linear_means_df <- linear_means %>%
   as_tibble() %>%
   select(c(1:5)) %>%
   mutate_if(is.factor, as.character) %>%
   rename(Linear=emmean)
```

#### Logistic

```{r}
logistic_means <- emmeans::emmeans(
  logistic_fit,
  c('feat_ext', 'learn_alg', 'conf_1', 'conf_2'),
  type='response')
```

```{r}
logistic_means_df <- logistic_means %>%
  as_tibble() %>%
  select(c(1:5)) %>%
  mutate_if(is.factor, as.character) %>%
  rename(Logistic=prob)
```

#### Comparison

```{r, warning=F, message=F}
(comparison <- observations %>%
  group_by(feat_ext, learn_alg, conf_1, conf_2) %>%
  summarise(Ability=unique(ability),
            Accuracy=mean(y)) %>%
  inner_join(linear_means_df,
             by=c('feat_ext', 'learn_alg', 'conf_1', 'conf_2'),
            ) %>%
  inner_join(logistic_means_df,
             by=c('feat_ext', 'learn_alg', 'conf_1', 'conf_2')))
```

```{r}
lin_log_p <- comparison %>%
  ggplot() +
  geom_point(aes(x=Linear, y=Logistic), alpha=0.6, size=2) +
  theme_bw() +
  coord_fixed(xlim=c(0,1), ylim=c(0,1)) +
  annotate("text", x=0.8, y=0.05,
    label="paste(italic(R) ^ 2, \" = .997\")",
    parse = TRUE)
lin_ab_p <- comparison %>%
  ggplot() +
  geom_point(aes(x=Linear, y=Ability), alpha=0.6, size=2) +
  theme_bw() +
  coord_fixed(xlim=c(0,1), ylim=c(0,1)) +
  annotate("text", x=0.8, y=0.05,
    label="paste(italic(R) ^ 2, \" = .999\")",
    parse = TRUE)
log_ab_p <- comparison %>%
  ggplot() +
  geom_point(aes(x=Logistic, y=Ability), alpha=0.6, size=2) +
  theme_bw() +
  coord_fixed(xlim=c(0,1), ylim=c(0,1)) +
  annotate("text", x=0.8, y=0.05,
    label="paste(italic(R) ^ 2, \" = .998\")",
    parse = TRUE)
```

```{r}
lin_log_p + lin_ab_p + log_ab_p
```

### Contrasts

#### Linear

```{r}
emmeans::contrast(linear_means, type='response', method='pairwise')
```

```{r}
(linear_contrasts_conf <- emmeans::contrast(
  emmeans::emmeans(linear_fit, c('conf_1', 'conf_2'), 
                   by =c('learn_alg', 'feat_ext'), type="response"),
  type="response"))
```

```{r}
linear_contrasts_conf_p <- linear_contrasts_conf %>% plot() +
    facet_grid(rows=vars(learn_alg, feat_ext),
               labeller=label_both, scales='free_y') +
    theme_bw() +
    labs(x='Estimate', y='Contrast') +
    ggtitle('Linear Contrasts')
```



#### Logistic

```{r}
(logistic_contrasts_conf <- emmeans::contrast(
  emmeans::emmeans(logistic_fit, c('conf_1', 'conf_2'), 
                   by =c('learn_alg', 'feat_ext'), type="response"),
  type="response"))
```

```{r}
logistic_contrasts_conf_p <- logistic_contrasts_conf %>% plot() +
    facet_grid(rows=vars(learn_alg, feat_ext), 
               labeller=label_both, scales='free_y') +
    theme_bw() +
    labs(x='Odds Ratio', y='Contrast') +
    ggtitle('Logistic Contrasts')
```

### Comparison

```{r}
(linear_contrasts_conf_p) + 
  (logistic_contrasts_conf_p + 
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank()))
```


## Benchmarking


```{r}
rbenchmark::benchmark(
  "linear" = {
    l <- lmerTest::lmer(model, data=measurements)},
  "logistic" = {
    l <- lme4::glmer(
      model,
      family="binomial",
      data=observations,
      control=lme4::glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=1e6)))},
  replications = 10,
  columns = c("test", "replications", "elapsed",
              "relative", "user.self", "sys.self"))

```